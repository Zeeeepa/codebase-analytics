"""
Comprehensive Codebase Analytics API - Single Endpoint Architecture
This module provides a unified codebase analysis endpoint that consolidates
all analysis capabilities into one powerful interface.
"""

import time
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import modal
from graph_sitter.core.codebase import Codebase

# Import analysis functions and models
from .analysis import (
    detect_entrypoints,
    analyze_code_issues,
    identify_critical_files,
    build_dependency_graph
)
from .metrics import (
    calculate_comprehensive_metrics,
    get_most_important_functions
)
from .enhanced_analysis import (
    generate_repository_analysis_report
)
from .models import (
    CodebaseAnalysisRequest,
    CodebaseAnalysisResponse,
    CodebaseAnalysis,
    AnalysisSummary,
    IssueSeverity,
    IssueType
)

# Modal setup for deployment
image = (
    modal.Image.debian_slim()
    .apt_install("git")
    .pip_install(
        "codegen", "fastapi", "uvicorn", "gitpython", "requests", "pydantic", "datetime"
    )
)

app = modal.App(name="analytics-app", image=image)
fastapi_app = FastAPI(
    title="Comprehensive Codebase Analytics API",
    description="Advanced codebase analysis with comprehensive issue detection and insights",
    version="2.0.0"
)

fastapi_app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


def create_analysis_summary(
    issues: List[Any],
    entry_points: List[Any],
    critical_files: List[Any],
    function_metrics: List[Any],
    class_metrics: List[Any],
    file_metrics: List[Any]
) -> AnalysisSummary:
    """Create a comprehensive analysis summary."""
    
    # Count issues by severity and type
    issues_by_severity = {}
    issues_by_type = {}
    
    for issue in issues:
        severity = issue.severity
        issue_type = issue.type
        
        issues_by_severity[severity] = issues_by_severity.get(severity, 0) + 1
        issues_by_type[issue_type] = issues_by_type.get(issue_type, 0) + 1
    
    critical_issues_count = issues_by_severity.get(IssueSeverity.CRITICAL, 0)
    high_priority_issues_count = (
        issues_by_severity.get(IssueSeverity.CRITICAL, 0) + 
        issues_by_severity.get(IssueSeverity.HIGH, 0)
    )
    
    # Calculate averages
    total_complexity = sum(getattr(f, 'cyclomatic_complexity', 0) for f in function_metrics)
    avg_complexity = total_complexity / len(function_metrics) if function_metrics else 0
    
    total_maintainability = sum(getattr(f, 'maintainability_index', 0) for f in function_metrics)
    avg_maintainability = total_maintainability / len(function_metrics) if function_metrics else 0
    
    total_loc = sum(getattr(f, 'lines_of_code', 0) for f in file_metrics)
    
    # Count files with issues
    files_with_issues = len(set(issue.file_path for issue in issues))
    
    return AnalysisSummary(
        total_issues=len(issues),
        issues_by_severity=issues_by_severity,
        issues_by_type=issues_by_type,
        files_with_issues=files_with_issues,
        critical_issues_count=critical_issues_count,
        high_priority_issues_count=high_priority_issues_count,
        total_files=len(file_metrics),
        total_functions=len(function_metrics),
        total_classes=len(class_metrics),
        total_lines_of_code=total_loc,
        average_complexity=avg_complexity,
        average_maintainability=avg_maintainability,
        entry_points_count=len(entry_points),
        critical_files_count=len(critical_files)
    )


@fastapi_app.post("/codebase_analysis", response_model=CodebaseAnalysisResponse)
async def comprehensive_codebase_analysis(request: CodebaseAnalysisRequest) -> CodebaseAnalysisResponse:
    """
    üéØ **SINGLE COMPREHENSIVE CODEBASE ANALYSIS ENDPOINT**
    
    This unified endpoint provides complete codebase analysis including:
    
    ‚úÖ **Comprehensive Issue Detection** - All 169+ issues with full context
    ‚úÖ **Critical File Identification** - Most important files with importance scoring  
    ‚úÖ **Entry Point Detection** - All entry points with confidence scoring
    ‚úÖ **Function Analysis** - Most important functions using Halstead metrics
    ‚úÖ **Dependency Graph Analysis** - Complete architectural insights
    ‚úÖ **Structured Storage Format** - Ready for CI/CD integration
    
    **Example Response Format:**
    ```json
    {
        "success": true,
        "analysis": {
            "summary": {
                "total_issues": 182,
                "critical_issues_count": 11,
                "files_with_issues": 23
            },
            "issues": [
                {
                    "id": "complexity_a1b2c3d4",
                    "type": "complexity_issue", 
                    "severity": "critical",
                    "file_path": "/path/to/file.py",
                    "line_number": 45,
                    "function_name": "complex_function",
                    "message": "High cyclomatic complexity: 28",
                    "interconnected_context": {
                        "dependencies": [...],
                        "dependents": [...],
                        "call_graph": {...}
                    },
                    "fix_suggestions": [...]
                }
            ],
            "critical_files": [...],
            "entry_points": [...],
            "function_metrics": [...]
        }
    }
    ```
    """
    
    start_time = time.time()
    
    try:
        # Load codebase using graph-sitter
        codebase = Codebase.from_repo(request.repo_url)
        
        # Initialize results containers
        issues = []
        entry_points = []
        critical_files = []
        function_metrics = []
        class_metrics = []
        file_metrics = []
        dependency_graph = None
        errors = []
        
        # 1. üîç COMPREHENSIVE ISSUE DETECTION
        if request.include_issues:
            try:
                issues = analyze_code_issues(codebase, max_issues=request.max_issues)
                
                # Filter by severity if specified
                if request.severity_filter:
                    issues = [issue for issue in issues if issue.severity in request.severity_filter]
                    
            except Exception as e:
                errors.append(f"Issue analysis failed: {str(e)}")
        
        # 2. üéØ ENTRY POINT DETECTION  
        if request.include_entry_points:
            try:
                entry_points = detect_entrypoints(codebase)
            except Exception as e:
                errors.append(f"Entry point detection failed: {str(e)}")
        
        # 3. üìä CRITICAL FILE IDENTIFICATION
        if request.include_critical_files:
            try:
                critical_files = identify_critical_files(codebase)
            except Exception as e:
                errors.append(f"Critical file analysis failed: {str(e)}")
        
        # 4. üìà COMPREHENSIVE METRICS CALCULATION
        if request.include_metrics:
            try:
                metrics_result = calculate_comprehensive_metrics(codebase)
                function_metrics = metrics_result.get('function_metrics', [])
                class_metrics = metrics_result.get('class_metrics', [])
                file_metrics = metrics_result.get('file_metrics', [])
            except Exception as e:
                errors.append(f"Metrics calculation failed: {str(e)}")
        
        # 5. üï∏Ô∏è DEPENDENCY GRAPH ANALYSIS
        if request.include_dependency_graph:
            try:
                dependency_graph = build_dependency_graph(codebase)
            except Exception as e:
                errors.append(f"Dependency graph analysis failed: {str(e)}")
        
        # 6. üìã CREATE COMPREHENSIVE ANALYSIS SUMMARY
        summary = create_analysis_summary(
            issues, entry_points, critical_files, 
            function_metrics, class_metrics, file_metrics
        )
        
        # 7. üèóÔ∏è BUILD STRUCTURED ANALYSIS RESULT
        analysis_duration = time.time() - start_time
        
        # Group issues by file for better organization
        issues_by_file = {}
        for issue in issues:
            file_path = issue.file_path
            if file_path not in issues_by_file:
                issues_by_file[file_path] = []
            issues_by_file[file_path].append(issue)
        
        # Create the comprehensive analysis object
        analysis = CodebaseAnalysis(
            repo_url=request.repo_url,
            analysis_timestamp=datetime.now(),
            analysis_duration=analysis_duration,
            summary=summary,
            issues=issues,
            issues_by_file=issues_by_file,
            function_metrics=function_metrics,
            class_metrics=class_metrics,
            file_metrics=file_metrics,
            entry_points=entry_points,
            critical_files=critical_files,
            dependency_graph=dependency_graph,
            repository_info={
                "total_files": len(list(codebase.files)),
                "total_functions": len(list(codebase.functions)),
                "total_classes": len(list(codebase.classes)),
                "analysis_timestamp": datetime.now().isoformat()
            },
            analysis_config={
                "include_issues": request.include_issues,
                "include_entry_points": request.include_entry_points,
                "include_critical_files": request.include_critical_files,
                "include_metrics": request.include_metrics,
                "include_dependency_graph": request.include_dependency_graph,
                "max_issues": request.max_issues,
                "severity_filter": request.severity_filter,
                "file_extensions": request.file_extensions
            },
            errors=errors
        )
        
        return CodebaseAnalysisResponse(
            success=True,
            analysis=analysis,
            processing_time=analysis_duration
        )
        
    except Exception as e:
        return CodebaseAnalysisResponse(
            success=False,
            error_message=f"Codebase analysis failed: {str(e)}",
            processing_time=time.time() - start_time
        )


@fastapi_app.get("/health")
async def health_check():
    """Health check endpoint to verify API status."""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "2.0.0",
        "features": {
            "comprehensive_issue_detection": True,
            "critical_file_identification": True,
            "entry_point_detection": True,
            "dependency_graph_analysis": True,
            "structured_analysis_storage": True,
            "halstead_metrics": True,
            "interconnected_context": True
        }
    }


@fastapi_app.post("/generate_report")
async def generate_enhanced_report(request: CodebaseAnalysisRequest) -> Dict[str, Any]:
    """
    üéØ **ENHANCED REPOSITORY ANALYSIS REPORT GENERATOR**
    
    Generate a comprehensive, human-readable repository analysis report with:
    
    ‚úÖ **Directory Tree Visualization** - Complete project structure with issue indicators
    ‚úÖ **Critical Issues Detection** - All critical issues with context and suggestions
    ‚úÖ **Inheritance Analysis** - Classes with deep inheritance hierarchies
    ‚úÖ **Automatic Resolution Suggestions** - AI-powered fix recommendations
    ‚úÖ **Graph-Sitter Integration** - Leverages pre-computed dependency graphs
    ‚úÖ **Actionable Insights** - Prioritized recommendations for improvement
    
    Perfect for:
    - Code review reports
    - Technical debt assessment
    - Architecture documentation
    - CI/CD integration
    """
    
    start_time = time.time()
    
    try:
        # Load codebase using graph-sitter
        codebase = Codebase.from_repo(request.repo_url)
        
        # Generate the enhanced report
        report_content = generate_repository_analysis_report(codebase, request.repo_url)
        
        processing_time = time.time() - start_time
        
        return {
            "success": True,
            "report": report_content,
            "processing_time": processing_time,
            "repo_url": request.repo_url,
            "generated_at": datetime.now().isoformat(),
            "features_used": [
                "Directory tree visualization",
                "Critical issues detection", 
                "Inheritance analysis",
                "Automatic resolution suggestions",
                "Graph-sitter integration"
            ]
        }
        
    except Exception as e:
        return {
            "success": False,
            "error_message": f"Report generation failed: {str(e)}",
            "processing_time": time.time() - start_time
        }


@fastapi_app.get("/")
async def root():
    """Root endpoint with API information."""
    return {
        "name": "Comprehensive Codebase Analytics API",
        "version": "2.0.0",
        "description": "Advanced codebase analysis with comprehensive issue detection",
        "endpoints": {
            "main": "/codebase_analysis",
            "enhanced_report": "/generate_report",
            "health": "/health",
            "docs": "/docs"
        },
        "features": [
            "üîç Comprehensive Issue Detection - All issues with full context",
            "üìä Critical File Identification - Importance scoring and metrics", 
            "üéØ Entry Point Detection - All entry points with confidence scoring",
            "üìà Advanced Function Analysis - Halstead metrics and complexity",
            "üï∏Ô∏è Dependency Graph Analysis - Complete architectural insights",
            "üèóÔ∏è Structured Storage Format - Ready for CI/CD integration",
            "üìã Enhanced Report Generation - Human-readable analysis reports"
        ]
    }


# Modal App Deployment
@app.function(image=image)
@modal.asgi_app()
def fastapi_modal_app():
    return fastapi_app


if __name__ == "__main__":
    # This allows running the app locally for development without Modal
    # Example: uvicorn api:fastapi_app --reload
    pass
